vcl 4.1;

import std;
import directors;
import xkey;

{{ if eq (getenv "BACKEND_PROBE") "true" }}
probe delivery_probe {
  .url = "{{ getenv "BACKEND_PROBE_URL" }}";
  .interval = {{ getenv "BACKEND_PROBE_INTERVAL" }};
  .timeout = {{ getenv "BACKEND_PROBE_TIMEOUT" }};
  .window = {{ getenv "BACKEND_PROBE_WINDOW" }};
  .threshold = {{ getenv "BACKEND_PROBE_THRESHOLD" }};
  .initial = {{ getenv "BACKEND_PROBE_THRESHOLD" }};
}
{{ end }}

{{ $BACKENDS := (split (getenv "BACKEND") ",") }}
{{ $REMOTE_BACKENDS := (split (getenv "REMOTE_BACKEND") ",") }}

{{ $ERROR_PAGE := getenv "ERROR_PAGE" "" }}
{{ $ERROR_PAGE_SEG := split $ERROR_PAGE "/" }}
{{ $IS_ERROR_PAGE_REMOTE := eq "http:" (index $ERROR_PAGE_SEG 0) }}
{{ define "ERROR_PAGE_PATH" -}}
  {{- $ERROR_PAGE := getenv "ERROR_PAGE" "" -}}
  {{- $ERROR_PAGE_SEG := split $ERROR_PAGE "/" -}}
  {{- $IS_ERROR_PAGE_REMOTE := eq "http:" (index $ERROR_PAGE_SEG 0) -}}
  {{- if $IS_ERROR_PAGE_REMOTE -}}
    {{- replace $ERROR_PAGE (printf "http://%s" (index $ERROR_PAGE_SEG 2)) "" 1 -}}
  {{- else -}}
    {{- $ERROR_PAGE -}}
  {{- end -}}
{{- end -}}

{{ if $IS_ERROR_PAGE_REMOTE }}
backend backend_error {
  {{- $backend := (split (index $ERROR_PAGE_SEG 2) ":") }}
  .host = "{{ index $ERROR_PAGE_SEG 2 }}";
  .port = "{{ if eq 2 (len $backend) }}{{ index $backend 1 }}{{ else }}80{{ end }}";
}
{{ end }}

{{ range $backendIndex, $hostnameWithPort := $BACKENDS }}
  {{- $backend := (split $hostnameWithPort ":") }}
  {{ range $ipIndex, $ip := lookupIP (index $backend 0) }}
backend backend_delivery_{{ $backendIndex }}_{{ $ipIndex }} {
  .host = "{{ $ip }}";
  .port = "{{ if eq 2 (len $backend) }}{{ index $backend 1 }}{{ else }}80{{ end }}";

  .max_connections        = {{ getenv "BACKEND_MAX_CONNECTIONS" }};
  .first_byte_timeout     = {{ getenv "BACKEND_FIRST_BYTES_TIMEOUT" }}; # How long to wait before we receive a first byte from our backend?
  .between_bytes_timeout  = {{ getenv "BACKEND_BETWEEN_BYTES_TIMEOUT" }};  # Max time to wait for next package in an http response
  .connect_timeout        = {{ getenv "BACKEND_CONNECT_TIMEOUT" }};  # How long to wait for a backend connection?
  {{ if eq (getenv "BACKEND_PROBE") "true" }}.probe = delivery_probe;{{ end }}
}
  {{ end }}
{{ end }}

{{ if (getenv "REMOTE_BACKEND") }}
  # Remote backends are unmonitored backends that only
  {{ range $backendIndex, $hostnameWithPort := $REMOTE_BACKENDS }}
    {{ $backend := (split $hostnameWithPort ":") }}

    {{ range $ipIndex, $ip := lookupIP (index $backend 0) }}
backend remote_{{ $backendIndex }}_{{ $ipIndex }} {
  .host = "{{ $ip }}";
  .port = "{{ if eq 2 (len $backend) }}{{ index $backend 1 }}{{ else }}80{{ end }}";
}
    {{ end }}
  {{ end }}
{{ end }}

# allowed to purge
acl purge {
  "localhost";
  "127.0.0.1";
  "::1";
  "172.17.0.0/24"; # Docker Network range
  "212.51.140.235"; # Livingdocs
  "212.51.155.165"; # Marc
}

sub vcl_init {
  new delivery = directors.round_robin();
  {{- range $backendIndex, $hostnameWithPort := $BACKENDS -}}
    {{- $backend := (split $hostnameWithPort ":") -}}
    {{ range $ipIndex, $ip := lookupIP (index $backend 0) }}
  delivery.add_backend(backend_delivery_{{ $backendIndex }}_{{ $ipIndex }});
    {{- end -}}
  {{- end }}
}

sub vcl_recv {
  # Allow purging
  if (req.method == "PURGE") {
    # purge is an ACL defined above, we check the ip is in there
    if (!client.ip ~ purge) {
      return (synth(405, "This IP is not allowed to send PURGE requests."));
    }

    if (req.http.xkey) {
      set req.http.n-gone = xkey.softpurge(req.http.xkey);
      return (synth(200, "Invalidated "+req.http.n-gone+" objects"));
    } else {
      return (purge);
    }
  }

  if (req.http.Error-Status) {
    set req.http.host = "error";
    {{ if $ERROR_PAGE }}set req.url = "{{ template "ERROR_PAGE_PATH" }}";{{ end }}
    set req.backend_hint = {{ if $IS_ERROR_PAGE_REMOTE }}backend_error{{ else }}delivery.backend(){{ end }};
  } else {
    {{ if (getenv "REMOTE_BACKEND") }}
      {{ range $backendIndex, $hostnameWithPort := $REMOTE_BACKENDS }}
        {{- $backend := (split $hostnameWithPort ":") }}
        {{- $hostname := (index $backend 0) }}

    if (req.http.host == "{{ $hostname }}") {
        {{ range $ipIndex, $ip := lookupIP $hostname }}
      set req.backend_hint = remote_{{ $backendIndex }}_{{ $ipIndex }};
        {{ end }}
    }
      {{ end }}
    {{ end }}

    if (!req.backend_hint) {
      set req.backend_hint = delivery.backend();
    }
  }

  # Support websockets
  if (req.http.upgrade ~ "(?i)websocket") { return (pipe); }

  # Only cache GET or HEAD requests. This makes sure the POST requests are always passed.
  if (req.method != "GET" && req.method != "HEAD" && req.method != "OPTIONS") { return (pass); }

  # Some generic URL cleanup, useful for all templates that follow
  # First remove the Google Analytics added parameters, useless for our backend
  if (req.url ~ "(\?|&)(gclid|utm_[a-z]+)=") {
    set req.url = regsuball(req.url, "(gclid|utm_[a-z]+)=[-_A-z0-9+()%.]+&?", "");
  }

  # Strip a trailing ? if it exists
  if (req.url ~ "\?$") {
    set req.url = regsub(req.url, "\?$", "");
  }

  # Normalize the query arguments
  set req.url = std.querysort(req.url);

  # Nuke all cookies
  unset req.http.Cookie;
  unset req.http.X-Cache;

  return (hash);
}

// Websocket support
sub vcl_pipe {
  set req.http.X-Cache = "pipe";
  if (req.http.upgrade) {
    set bereq.http.upgrade = req.http.upgrade;
    set bereq.http.connection = req.http.connection;
  }
}

# Called after vcl_recv to create a hash value for the request. This is used
# as a key to look up the object in Varnish.
# These hash subs are executed in order, they should not return anything
# and the hashed data will later on get concatenated by the default vcl_hash.
sub vcl_hash {
  # Cache based on hostname or ip
  if (req.http.host) { hash_data(req.http.host); }
  else { hash_data(server.ip); }

  # Cache based on user agent
  if (req.http.User-Agent ~ "^[a-zA-Z0-9-]+$") { hash_data(req.http.User-Agent); }
  if (req.http.Authorization) { hash_data(req.http.Authorization); }

  # Cache based on url
  hash_data(req.url);
}

sub vcl_backend_fetch {
  if (bereq.retries > 0) {
    if (bereq.http.host == "error") { set bereq.backend = {{ if $IS_ERROR_PAGE_REMOTE }}backend_error{{ else }}delivery.backend(){{ end }}; }
    else { set bereq.backend = delivery.backend(); }
  }
  return (fetch);
}

# Handle the HTTP request coming from our backend
# Called after the response headers has been successfully retrieved from the backend.
sub vcl_backend_response {
  if (bereq.uncacheable) { return (deliver); }

  # We don't use any cookies, remove them to prevent security issues
  unset beresp.http.Set-Cookie;

  # Enable ESI for pages that request it
  if (beresp.http.Surrogate-Control ~ "ESI/1.0") {
    set beresp.do_esi = true;
  }

  # Make sure that varnish always saves the gzipped content, even
  # when the backend just returns raw text content
  if (beresp.http.content-type ~ "text/(plain|xml|css|html)"
      || beresp.http.content-type ~ "javascript"
      || beresp.http.content-type ~ "font-(ttf|opentype|woff)"
      || beresp.http.content-type ~ "application/vnd\.ms-fontobject"
      || beresp.http.content-type ~ "image/svg"
   ) {
    set beresp.do_gzip = true;
  }

  if (beresp.http.content-type ~ "(webp|jpeg|bmp|tiff|gif|png|woff|tar|rar|zip|pdf)") {
    set beresp.do_stream = true;
  }

  # Directly pass 50x responses to handle_request_errors
  if (beresp.status >= 500 && beresp.status <= 504) {
    if (bereq.is_bgfetch) { return (abandon); }
    if (bereq.retries < 1) { return (retry); }

    {{ if $ERROR_PAGE }}
    if (bereq.http.host == "error") { return (abandon); }
    set beresp.ttl = 15s;
    set beresp.http.Restart-With-Error-Status = beresp.status;
    return (deliver);
    {{ else }}
    set beresp.ttl = 15s;
    return (deliver);
    {{ end }}
  }

  if (bereq.http.host == "error") {
    set beresp.grace = 30d;
    set beresp.ttl = 5m;
    return (deliver);
  }

  # Directly pass 404 statuses, cache for 5s to throttle requests to a backend
  if (beresp.status == 404) {
    set beresp.ttl = 10s;
    return (deliver);
  }

  # Allow stale content, in case the backend goes down.
  # We make Varnish keep all objects for 24 hours (default_grace config) beyond their TTL
  if (beresp.http.X-Varnish-Grace) { set beresp.grace = std.duration(beresp.http.X-Varnish-Grace + "s"); }
}

# Called before a cached/fresh object is delivered to the client.
sub vcl_deliver {
  if (resp.http.Restart-With-Error-Status) {
    set req.http.Error-Status = resp.http.Restart-With-Error-Status;
    return (restart);
  } else if (req.http.host == "error") {
    set resp.status = std.integer(req.http.Error-Status, 500);
  }

  # Add Cache Grace Info to Response (set in vcl_hit)
  if (req.http.X-Cache-Grace) { set resp.http.X-Cache-Grace = req.http.X-Cache-Grace; }
  else { set resp.http.X-Cache-Grace = "NONE"; }

  # Add debug header to see if it's a HIT/MISS and the number of hits, disable when not needed
  if (obj.hits > 0) { set resp.http.X-Cache = "HIT"; }
  else { set resp.http.X-Cache = "MISS"; }

  # Please note that obj.hits behaviour changed in 4.0, now it counts per
  # objecthead, not per object and obj.hits may not be reset in some cases where
  # bans are in use. See bug 1492 for details. So take hits with a grain of salt
  set resp.http.X-Cache-Hits = obj.hits;

  # Disable ETag for ESI pages as the ETag of subrequests doesn't propagate to the parent
  # Pages served would always rely on the cache of the main page and therefore
  # never refresh, even if the subrequest is updated
  if (resp.http.Surrogate-Control ~ "ESI/1.0") {
    unset resp.http.ETag;
    unset resp.http.Last-Modified;
  }

  # Remove some headers
  unset resp.http.Server;
  unset resp.http.X-Varnish;
  unset resp.http.Via;
  unset resp.http.X-Generator;
  unset resp.http.Surrogate-Control;
  unset resp.http.X-Varnish-Grace;

  return (deliver);
}

sub vcl_hit {
  if (obj.ttl >= 0s) {
    set req.http.X-Cache-Grace = "HIT";
  } else if (obj.ttl + obj.grace > 0s) {
    set req.http.X-Cache-Grace = "MISS";
  } else if (!std.healthy(req.backend_hint)) {
    return (synth(503));
  } else {
    set req.http.X-Cache-Grace = "STALE";
  }

  return (deliver);
}

sub vcl_purge {
  # Only handle actual PURGE HTTP methods, everything else is discarded
  if (req.method != "PURGE") {
    # restart request
    set req.http.X-Purge = "Yes";
    return (restart);
  }
}

sub vcl_backend_error {
  if (bereq.is_bgfetch) { return (abandon); }
  if (bereq.retries < 1) { return (retry); }

  {{ if $ERROR_PAGE }}
  if (bereq.http.host == "error") { return (abandon); }
  set beresp.ttl = 15s;
  set beresp.http.Restart-With-Error-Status = beresp.status;
  return (deliver);
  {{ else }}
  set beresp.ttl = 15s;
  set beresp.grace = 0s;
  return (retry);
  {{ end }}
}

sub vcl_synth {
  if (resp.status == 503 && req.http.host != "error") {
    if (resp.http.Restart-With-Error-Status) {set req.http.Error-Status = resp.http.Restart-With-Error-Status;}
    else {set req.http.Error-Status = resp.status;}
    return(restart);
  }

  if (req.http.Content-Type ~ "application/json") {
    set resp.http.Content-Type = "application/json; charset=utf-8";
    synthetic(regsub(regsub(regsuball("{'status':_s,'error':'_e'}", "'", {"""}), "_s", resp.status), "_e", resp.reason));
  } else {
    set resp.http.Content-Type = "text/html; charset=utf-8";
    synthetic({"<!DOCTYPE html><html><head><title>"} + resp.status + " " + resp.reason + {"</title></head><body><h1>Error "} + resp.status + " " + resp.reason + {"</h1></body></html>"});
  }

  return (deliver);
}

sub vcl_fini {
  return (ok);
}
